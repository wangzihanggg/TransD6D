local_rank: 0
cls_id in lm_dataset.py 1
render data length:  0
Warning: Trainnig without rendered data will hurt model performance
Please generate rendered data from https://github.com/ethnhe/raster_triangle.
fused data length:  0
Warning: Trainnig without fused data will hurt model performance
Please generate fused data from https://github.com/ethnhe/raster_triangle.
train_dataset_size:  186
cls_id in lm_dataset.py 1
test_dataset_size:  1050
Number of model parameters:  37960145
local_rank: 0
Selected optimization level O0:  Pure FP32 training.
Defaults for this optimization level are:
enabled                : True
opt_level              : O0
cast_model_type        : torch.float32
patch_torch_functions  : False
keep_batchnorm_fp32    : None
master_weights         : False
loss_scale             : 1.0
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O0
cast_model_type        : torch.float32
patch_torch_functions  : False
keep_batchnorm_fp32    : None
master_weights         : False
loss_scale             : 1.0
==> Checkpoint 'train_log/test_1/ape/checkpoints/ape.pth.tar' not found
Totally train 500 iters per gpu.
/home/wangzihanggg/codespace/SwinDePose/swin_de_pose/mmsegmentation/mmseg/models/decode_heads/decode_head.py:94: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert seg_logist into a predictionapplying a threshold
  warnings.warn('For binary segmentation, we suggest using'
/home/wangzihanggg/codespace/SwinDePose/swin_de_pose/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.
  warnings.warn(
/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.parallel.convert_syncbn_model is deprecated and will be removed by the end of February 2023. Use `torch.nn.SyncBatchNorm.convert_sync_batchnorm`.
  warnings.warn(msg, DeprecatedFeatureWarning)
/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
  0%|                                                                                                                                                                                               | 0/25 [00:00<?, ?it/s]
  0%|                                                                                                                                                                                               | 0/25 [00:08<?, ?it/s]
Traceback (most recent call last):
  File "apps/train_lm.py", line 750, in <module>
    train()
  File "apps/train_lm.py", line 732, in train
    trainer.train(
  File "apps/train_lm.py", line 513, in train
    _, loss, res = self.model_fn(self.model, batch, it=it)
  File "apps/train_lm.py", line 190, in model_fn
    end_points = model(cu_dt)
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/apex/amp/_initialize.py", line 198, in new_fwd
    output = old_fwd(*applier(args, input_caster),
  File "/home/wangzihanggg/codespace/SwinDePose/swin_de_pose/models/SwinDePose.py", line 202, in forward
    feat_nrm = self.swin_ffb(inputs['nrm_angles']) # [1,96,120,160]->[1,192,60,80]->[1,384,30,40]->[1,768,15,20]
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wangzihanggg/codespace/SwinDePose/swin_de_pose/mmsegmentation/mmseg/models/backbones/swin.py", line 748, in forward
    x, hw_shape, out, out_hw_shape = stage(x, hw_shape)
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wangzihanggg/codespace/SwinDePose/swin_de_pose/mmsegmentation/mmseg/models/backbones/swin.py", line 456, in forward
    x = block(x, hw_shape)
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wangzihanggg/codespace/SwinDePose/swin_de_pose/mmsegmentation/mmseg/models/backbones/swin.py", line 375, in forward
    x = _inner_forward(x)
  File "/home/wangzihanggg/codespace/SwinDePose/swin_de_pose/mmsegmentation/mmseg/models/backbones/swin.py", line 362, in _inner_forward
    x = self.attn(x, hw_shape)
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wangzihanggg/codespace/SwinDePose/swin_de_pose/mmsegmentation/mmseg/models/backbones/swin.py", line 231, in forward
    attn_windows = self.w_msa(query_windows, mask=attn_mask)
  File "/home/wangzihanggg/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wangzihanggg/codespace/SwinDePose/swin_de_pose/mmsegmentation/mmseg/models/backbones/swin.py", line 116, in forward
    x = (attn @ v).transpose(1, 2).reshape(B, N, C)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 5.81 GiB total capacity; 3.97 GiB already allocated; 33.19 MiB free; 4.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF